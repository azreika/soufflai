#define EULER 2.71828
#define ETA 0.5

.type NodeID = number
.type EdgeID = number

/***
 * Configuration
 */
.decl targetValue(id:NodeID, target:float)
.decl nodeBias(id:NodeID, value:float)
.decl node(id:NodeID, layer:number, index:number)
.decl edge(id:EdgeID, x:NodeID, y:NodeID, weight:float)

.input targetValue
.input nodeBias
.input node
.input edge

/***
 * Forward propagation
 */
.decl forward(id:NodeID, value:float)
// value of dummy start node is 1
forward(-1, 1).
forward(id, value + bias) :-
    node(id, layer, _),
    nodeBias(id, bias),
    forwardInductive(id, value, index),
    // stopping index is index of max prev layer node
    index = max x : { node(_, layer-1, x) }.

.decl activatedForward(id:NodeID, value:float)
activatedForward(id, value) :-
    forward(id, initial),
    node(id, layer, _),
    max_layer = max l : node(_, l, _),
    sigmoid = 1/(1+EULER^(-initial)),

    // sigmoid for output layer
    ((layer = max_layer, value = sigmoid);

    // sigmoid for hidden layers
     (layer < max_layer, layer > 0, value = sigmoid);

    // input nodes shouldnt change
     (layer <= 0, value = initial)).

// Inductive step to sum up all incoming values
// Induces an ordering based on previous layer indices
.decl forwardInductive(id:NodeID, rolling_value:float, index:number)
forwardInductive(id, 0.0, -1) :- node(id, _, _).
forwardInductive(id, prev_value + x1_value * weight, index) :-
    forwardInductive(id, prev_value, prev_index),
    index = prev_index + 1,
    node(x1_id, _, index),
    edge(_, x1_id, id, weight),
    activatedForward(x1_id, x1_value).

/***
 * Back propagation
 */
.decl totalError(error:float)
totalError(error) :-
    error = 0.5 * (sum (x * x) : {
        x = target - actual,
        targetValue(id, target),
        activatedForward(id, actual)}).

.decl newEdgeWeight(id:EdgeID, weight:float)
newEdgeWeight(id, old_weight - ETA * deltaErrorVsWeight) :-
    edge(id, _, _, old_weight),
    edgeDeltaErrorVsOut(id, deltaErrorVsOut),
    edgeDeltaOutVsNet(id, deltaOutVsNet),
    edgeDeltaNetVsWeight(id, deltaNetVsWeight),
    deltaErrorVsWeight = deltaErrorVsOut * deltaOutVsNet * deltaNetVsWeight.
.output newEdgeWeight()

.decl edgeDeltaOutVsNet(id:EdgeID, delta:float)
edgeDeltaOutVsNet(id, delta) :-
    edge(id, _, y, _),
    activatedForward(y, out),
    delta = out * (1 - out).

.decl edgeDeltaNetVsWeight(id:EdgeID, delta:float)
edgeDeltaNetVsWeight(id, delta) :-
    edge(id, x, _, _),
    activatedForward(x, out),
    delta = out.

.decl edgeDeltaErrorVsOut(id:EdgeID, delta:float)
// For output layer
edgeDeltaErrorVsOut(id, delta) :-
    layer = max l : node(_, l, _),
    node(y, layer, _),
    targetValue(y, target),
    activatedForward(y, actual),
    edge(id, _, y, _),
    delta = actual - target.

// For hidden layers
edgeDeltaErrorVsOut(id, delta) :-
    edge(id, _, y, _),
    node(y, layer, _),
    edgeDeltaErrorVsOutInductive(id, delta, index),
    index = max idx : { node(_, layer+1, idx) }.

// Inductive relation to find dError/dOut for each hidden layer node
// Recursive sum aggregate of previous backpropagated error values
.decl edgeDeltaErrorVsOutInductive(id:EdgeID, rolling_delta:float, index:number)
edgeDeltaErrorVsOutInductive(id, 0, -1) :-
    edge(id, _, y, _),
    node(y, layer, _),
    layer < max l : node(_, l, _).

edgeDeltaErrorVsOutInductive(id, old_delta + cur_delta, index) :-
    edgeDeltaErrorVsOutInductive(id, old_delta, old_index),
    index = old_index + 1,
    edge(id, _, y, _),
    edge(next_id, y, z, sub_delta3),
    node(z, _, index),
    edgeDeltaErrorVsOut(next_id, sub_delta1),
    edgeDeltaOutVsNet(next_id, sub_delta2),
    cur_delta = sub_delta1 * sub_delta2 * sub_delta3.

/**
 * Output
 */
.output newEdgeWeight
.output totalError
